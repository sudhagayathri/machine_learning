{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d96a342",
   "metadata": {},
   "source": [
    "### TextBlob Library\n",
    "\n",
    "#### Features\n",
    "\n",
    "- Part-of-speech tagging\n",
    "- Tokenization (splitting text into words and sentences)\n",
    "- Word frequencies\n",
    "- Spelling correction\n",
    "- Word inflection (pluralization and singularization)\n",
    "- Sentiment analysis\n",
    "- n-grams\n",
    "- Classification (Naive Bayes, Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f4b8a",
   "metadata": {},
   "source": [
    "### Start\n",
    "\n",
    "#### Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "919e1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /home/justdial/anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/justdial/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/justdial/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in /home/justdial/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /home/justdial/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in /home/justdial/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391d492c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/justdial/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/justdial/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/justdial/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/justdial/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /home/justdial/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/justdial/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "#download default models in this library\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc725669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2786368",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextBlob(\"I am going to New York today. Will enjoy my vacation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f77b1",
   "metadata": {},
   "source": [
    "#### Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63fbceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('today', 'NN'),\n",
       " ('Will', 'MD'),\n",
       " ('enjoy', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('vacation', 'NN')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c17ab6",
   "metadata": {},
   "source": [
    "#### Explanation of the tags is as follows:\n",
    "\n",
    "- PRP: Personal pronoun\n",
    "- VBP: Verb, non-3rd person singular present\n",
    "- VBG: Verb, gerund or present participle\n",
    "- TO: Preposition or infinitival \"to\"\n",
    "- NNP: Proper noun, singular\n",
    "- NN: Noun, singular or mass\n",
    "- MD: Modal auxiliary\n",
    "- VB: Verb, base form\n",
    "- PRP$: Possessive pronoun\n",
    "- NN: Noun, singular or mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b215d",
   "metadata": {},
   "source": [
    "#### Tokenization: sentence and work tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6c7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I am going to New York today.\"), Sentence(\"Will enjoy my vacation\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0869af11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'am', 'going', 'to', 'New', 'York', 'today', 'Will', 'enjoy', 'my', 'vacation'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ceab620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vacation'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.words[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72cca91",
   "metadata": {},
   "source": [
    "#### Word inflection (pluralization and singularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692999b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vacations'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.words[-1].pluralize()   #in the same way singularize can also be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7f2a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ams'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.words[1].pluralize()   #in the same way singularize can also be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1eeef",
   "metadata": {},
   "source": [
    "#### Spelling correction and completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c669cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"May you have a good morning\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'May you havv a good mornin'\n",
    "text = TextBlob(data)\n",
    "text.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee632121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"A you had a good morning\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'Ma you hav a good mornin'\n",
    "text = TextBlob(data)\n",
    "text.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89c9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above is not that great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43beeb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('can', 1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "k = Word('can')\n",
    "k.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "711cc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.0 it means it is 100 % correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7ce626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('An', 0.5222764723832773),\n",
       " ('Man', 0.25205981080256334),\n",
       " ('Can', 0.1670735428745804),\n",
       " ('Ran', 0.049130302105584375),\n",
       " ('San', 0.003051571559353067),\n",
       " ('Van', 0.0028989929813854134),\n",
       " ('Fan', 0.0012206286237412267),\n",
       " ('Ban', 0.00091547146780592),\n",
       " ('Pan', 0.0006103143118706134),\n",
       " ('Dan', 0.0003051571559353067),\n",
       " ('Wan', 0.00015257857796765334),\n",
       " ('Nan', 0.00015257857796765334),\n",
       " ('Jan', 0.00015257857796765334)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = Word('Can')\n",
    "k.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f157f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33651d8c",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "In TextBlob, spell checking is based on the underlying WordNet lexical database. WordNet includes a collection of words along with their possible meanings or senses. When performing spell checking, TextBlob checks if the word exists in WordNet and provides suggestions based on the available senses.\n",
    "\n",
    "In the case of k = Word('can'), where \"can\" is lowercase, it is considered as a proper word, and it might not have multiple senses or suggestions in WordNet. Hence, the spellcheck result may return the word as correct without any suggestions.\n",
    "\n",
    "On the other hand, k = Word('Can'), where \"Can\" is in CamelCase, can have multiple senses or meanings in WordNet. The spellcheck result may provide suggestions based on alternative words or senses that are similar to \"Can\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6753a9",
   "metadata": {},
   "source": [
    "#### Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ffe068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies:\n",
      "Counter({'I': 1, 'love': 1, 'to': 1, 'code': 1, 'Coding': 1, 'is': 1, 'fun': 1, 'and': 1, 'rewarding': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "text = \"I love to code. Coding is fun and rewarding.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "word_frequencies = Counter(blob.words)\n",
    "print(\"Word Frequencies:\")\n",
    "print(word_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7b701b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies:\n",
      "Counter({'code': 2, 'I': 1, 'love': 1, 'to': 1, 'is': 1, 'fun': 1, 'and': 1, 'rewarding': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "text = \"I love to code. code is fun and rewarding.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "word_frequencies = Counter(blob.words)\n",
    "print(\"Word Frequencies:\")\n",
    "print(word_frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea82f7",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "720e7ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-1.0, subjectivity=1.0)\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "text = \"worst movie\"\n",
    "blob = TextBlob(text)\n",
    "sentiment = blob.sentiment\n",
    "print(sentiment)\n",
    "if sentiment.polarity>0.5:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c48683bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjectivity is actually reasoning with fact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336923da",
   "metadata": {},
   "source": [
    "#### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e43e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"सभी दोस्त एक साथ खेलते हैं\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"All friends play together\")\n",
    "b.translate(from_lang='en', to='hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc4fe9",
   "metadata": {},
   "source": [
    "#### Ngram handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af2f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: worst movie\n",
      "Word Tokenization: ['I', 'am', 'going', 'to', 'New', 'York', 'today', 'Will', 'enjoy', 'my', 'vacation']\n",
      "2-grams: [WordList(['I', 'am']), WordList(['am', 'going']), WordList(['going', 'to']), WordList(['to', 'New']), WordList(['New', 'York']), WordList(['York', 'today']), WordList(['today', 'Will']), WordList(['Will', 'enjoy']), WordList(['enjoy', 'my']), WordList(['my', 'vacation'])]\n"
     ]
    }
   ],
   "source": [
    "n = 2  # Set the value of 'n' for n-grams (e.g., 2 for bigrams, 3 for trigrams, etc.)\n",
    "\n",
    "blob = TextBlob(\"I am going to New York today. Will enjoy my vacation\")\n",
    "# Tokenize the text into words\n",
    "words = blob.words\n",
    "\n",
    "# Create n-grams\n",
    "ngrams = [words[i:i + n] for i in range(len(words) - n + 1)]\n",
    "\n",
    "print(\"Original Text:\"\n",
    "      , text)\n",
    "print(\"Word Tokenization:\", words)\n",
    "print(f\"{n}-grams:\", ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d28a702",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64a9acd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'cat', 'are', 'better', 'than', 'ran', 'dog']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"running cats are better than ran dogs\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Lemmatize the words\n",
    "lemmatized_words = [word.lemmatize() for word in blob.words]\n",
    "\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b19231",
   "metadata": {},
   "source": [
    "#### Write a function to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e371b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Hello! This is a simple example, showing how to clean data using TextBlob.\n",
      "Cleaned Text: hello simple example showing clean data using textblob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/justdial/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/justdial/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean the data\n",
    "def clean_data(text):\n",
    "    # Tokenize the text into words\n",
    "    blob = TextBlob(text)\n",
    "    words = blob.words\n",
    "\n",
    "    # Remove punctuation and stopwords, and convert words to lowercase in a single pass\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean_words = [word.lower() for word in words if word.lower() not in stop_words and word not in punctuation]\n",
    "\n",
    "    # Join the clean words back into a cleaned text\n",
    "    cleaned_text = \" \".join(clean_words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Test the clean_data function\n",
    "text_to_clean = \"Hello! This is a simple example, showing how to clean data using TextBlob.\"\n",
    "cleaned_text = clean_data(text_to_clean)\n",
    "print(\"Original Text:\", text_to_clean)\n",
    "print(\"Cleaned Text:\", cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98b4a3",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0ff3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a text classification system\n",
    "\n",
    "#Create a text classification system\n",
    "\n",
    "train = [\n",
    "    (\"I love this movie!\", \"positive\"),\n",
    "    (\"The food was delicious.\", \"positive\"),\n",
    "    (\"The service was terrible.\", \"negative\"),\n",
    "    (\"I had a great time at the party.\", \"positive\"),\n",
    "    (\"The product did not meet my expectations.\", \"negative\"),\n",
    "    (\"The weather is perfect today.\", \"positive\"),\n",
    "    (\"The customer support was unhelpful.\", \"negative\"),\n",
    "    (\"I feel disappointed with the outcome.\", \"negative\"),\n",
    "    (\"She is a talented musician.\", \"positive\"),\n",
    "    (\"The traffic jam ruined my morning.\", \"negative\"),\n",
    "    (\"The book is captivating.\", \"positive\"),\n",
    "    (\"The movie was boring and predictable.\", \"negative\"),\n",
    "    (\"I am extremely satisfied with the product.\", \"positive\"),\n",
    "    (\"The staff was friendly and helpful.\", \"positive\"),\n",
    "    (\"The hotel room was dirty and smelly.\", \"negative\"),\n",
    "    (\"The concert was amazing!\", \"positive\"),\n",
    "    (\"I regret buying this item.\", \"negative\"),\n",
    "    (\"The customer service was prompt and efficient.\", \"positive\"),\n",
    "    (\"The performance was lackluster.\", \"negative\")\n",
    "]\n",
    "\n",
    "test = [(\"The beach was crowded and noisy.\", \"negative\"),\n",
    "    (\"I had a fantastic experience at the amusement park.\", \"positive\"),\n",
    "    (\"The company's stock price plummeted.\", \"negative\"),\n",
    "    (\"The new design is innovative and user-friendly.\", \"positive\"),\n",
    "    (\"The job interview went well.\", \"positive\"),\n",
    "    (\"The website is slow and frustrating to use.\", \"negative\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here below we can see it is using its own model, we dont need to do any pre-processing, \n",
    "#like convertng categorical to numeric data, we dont need to use vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a19e1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab7ebf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single statement prediction\n",
    "\n",
    "cl.classify(\"good man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f753f403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7fe0579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.update(test)   #retraining the classifier object with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95a17f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d11488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a0653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
